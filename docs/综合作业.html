<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>&lt;center&gt;&#x57fa;&#x4e8e;&#x673a;&#x5668;&#x5b66;&#x4e60;&#x7684;&#x6587;&#x672c;&#x5206;&#x7c7b;&#x4e0e;&#x805a;&#x7c7b;&#x5206;&#x6790;&lt;&sol;center&gt;</title>
            <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only],
.vscode-high-contrast:not(.vscode-high-contrast-light) img[src$=\#gh-light-mode-only],
.vscode-high-contrast-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
            <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
<style>
:root {
  --color-note: #0969da;
  --color-tip: #1a7f37;
  --color-warning: #9a6700;
  --color-severe: #bc4c00;
  --color-caution: #d1242f;
  --color-important: #8250df;
}

</style>
<style>
@media (prefers-color-scheme: dark) {
  :root {
    --color-note: #2f81f7;
    --color-tip: #3fb950;
    --color-warning: #d29922;
    --color-severe: #db6d28;
    --color-caution: #f85149;
    --color-important: #a371f7;
  }
}

</style>
<style>
.markdown-alert {
  padding: 0.5rem 1rem;
  margin-bottom: 16px;
  color: inherit;
  border-left: .25em solid #888;
}

.markdown-alert>:first-child {
  margin-top: 0
}

.markdown-alert>:last-child {
  margin-bottom: 0
}

.markdown-alert .markdown-alert-title {
  display: flex;
  font-weight: 500;
  align-items: center;
  line-height: 1
}

.markdown-alert .markdown-alert-title .octicon {
  margin-right: 0.5rem;
  display: inline-block;
  overflow: visible !important;
  vertical-align: text-bottom;
  fill: currentColor;
}

.markdown-alert.markdown-alert-note {
  border-left-color: var(--color-note);
}

.markdown-alert.markdown-alert-note .markdown-alert-title {
  color: var(--color-note);
}

.markdown-alert.markdown-alert-important {
  border-left-color: var(--color-important);
}

.markdown-alert.markdown-alert-important .markdown-alert-title {
  color: var(--color-important);
}

.markdown-alert.markdown-alert-warning {
  border-left-color: var(--color-warning);
}

.markdown-alert.markdown-alert-warning .markdown-alert-title {
  color: var(--color-warning);
}

.markdown-alert.markdown-alert-tip {
  border-left-color: var(--color-tip);
}

.markdown-alert.markdown-alert-tip .markdown-alert-title {
  color: var(--color-tip);
}

.markdown-alert.markdown-alert-caution {
  border-left-color: var(--color-caution);
}

.markdown-alert.markdown-alert-caution .markdown-alert-title {
  color: var(--color-caution);
}

</style>
        
        </head>
        <body class="vscode-body vscode-light">
            <p><img src="file:///d:\CODE\temp-repo\comprehensive-operation\docs\images\title.svg" alt="图片1"></p>
<h1 id="基于机器学习的文本分类与聚类分析"><center>基于机器学习的文本分类与聚类分析</center></h1>
<h2 id="1-实验准备">1. 实验准备</h2>
<h3 id="11-数据来源">1.1 数据来源</h3>
<p>数据来源于老师发送的文件&quot;gastric.xlsx&quot;表格。该数据集包含250条胃部病理诊断记录，每条记录包含两个字段：Label（标签）和Text（病理诊断文本描述）。以下为5条数据样例：</p>
<table>
<thead>
<tr>
<th>Label</th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>（胃体小弯活检）粘膜慢性活动性萎缩性炎伴腺体中度肠化及糜烂，局灶腺体粘液样变及低级别上皮内瘤变。<br>（建议随诊、定期复查！）</td>
</tr>
<tr>
<td>1</td>
<td>（胃窦小弯）粘膜慢性活动性炎伴少量出血，另见少量炎性渗出，局灶腺体低级别上皮内瘤变。幽门螺旋杆菌（HP）：（阴性，-）。<br>（建议临床随访！）</td>
</tr>
<tr>
<td>1</td>
<td>慢性轻度萎缩性胃（窦小弯）炎伴腺体轻度肠化及浅表糜烂，局灶腺体低级别上皮内瘤变。幽门螺旋杆菌（HP）：（阴性，-）。<br>（建议临床随访！）</td>
</tr>
<tr>
<td>1</td>
<td>1、（胃窦小弯活检）粘膜慢性活动性炎伴浅表糜烂。<br>2、（胃体后壁活检）黏膜慢性炎伴局灶呈息肉样增生。<br>3、（胃窦体交界处大弯活检）粘膜慢性活动性炎伴浅表糜烂，局灶腺体低级别上皮内瘤变。<br>4、（胃体下部大弯活检）粘膜慢性活动性炎伴浅表糜烂，局灶腺体低级别上皮内瘤变。。<br>（建议治疗后复查！）</td>
</tr>
<tr>
<td>1</td>
<td>1、（胃角活检）粘膜慢性炎伴轻度肠化及少量出血、糜烂，局灶腺体低级别上皮内瘤变。<br>2、（胃窦小弯活检）粘膜慢性炎伴轻度肠化及少量出血、糜烂。<br>（建议随诊、定期复查！）</td>
</tr>
</tbody>
</table>
<h3 id="12-实验环境与工具">1.2 实验环境与工具</h3>
<ul>
<li><strong>编程语言</strong>: Python 3.9.23</li>
<li><strong>主要库</strong>: pandas, scikit-learn, openpyxl, jieba</li>
<li><strong>开发环境</strong>: Visual Studio Code, Anaconda3</li>
<li><strong>数据处理</strong>: 使用pandas读取Excel文件，scikit-learn进行机器学习建模</li>
</ul>
<h3 id="13-实验目标">1.3 实验目标</h3>
<ol>
<li>实现 KNN和SVM算法对病理诊断文本进行分类</li>
<li>实现 K-Means算法对病理诊断文本进行聚类</li>
</ol>
<h2 id="2-数据预处理与特征工程">2. 数据预处理与特征工程</h2>
<h3 id="21-数据加载与探索">2.1 数据加载与探索</h3>
<p>使用pandas库的<code>read_excel()</code>函数加载Excel文件，数据包含250行记录，每行包含Label（数值标签）和Text（中文病理诊断文本）两个字段。</p>
<h3 id="22-文本预处理">2.2 文本预处理</h3>
<p>使用jieba分词库对中文病理诊断文本进行分词处理，加载自定义停用词表，过滤无关词汇，同时额外加上对换行符、括号、空格等特殊字符的过滤。分词结束后将每篇文本转换为以空格分隔的词汇序列。</p>
<h3 id="23-文本向量化---tf-idf">2.3 文本向量化 - TF-IDF</h3>
<p>采用scikit-learn的<code>TfidfVectorizer</code>进行文本特征提取，首先自动处理分词后的文本，构建词汇表，同时考虑词频(TF)和逆文档频率(IDF)，突出重要词汇。此处不是以常见的“表格”或“数组”形式展示的，而是以稀疏矩阵（sparse matrix）的压缩格式打印出来的，只显示那些非零的元素，以及它们所在的行、列索引和对应的值。因为大多数句子中，绝大多数词语是不会出现的，也就是<code>TF-IDF = 0</code>。如果把整个250×N的矩阵（比如<code>N=1000+</code>）全部打印出来，会有海量0值，既浪费空间又难以阅读。所以<code>scipy.sparse</code>只打印非零元素，突出关键数据。特征维度根据根据实际词汇数量自动确定。</p>
<h3 id="24-数据集划分">2.4 数据集划分</h3>
<p>使用<code>train_test_split</code>函数分层抽样，将数据集的测试集比例划分为20%。</p>
<h2 id="3-分类算法实验">3. 分类算法实验</h2>
<h3 id="31-knn分类算法">3.1 KNN分类算法</h3>
<h4 id="311-算法原理">3.1.1 算法原理</h4>
<p>K最近邻（K-Nearest Neighbors, KNN）算法基于实例学习，通过计算样本间的欧式距离进行分类，n维空间中的欧式距离的通用计算公式如下（A、B为该空间中的任意两点）：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">B</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">d(\mathbf{A}, \mathbf{B}) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathbf">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1568em;vertical-align:-1.2777em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791em;"><span class="svg-align" style="top:-5.1168em;"><span class="pstrut" style="height:5.1168em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391em;"><span class="pstrut" style="height:5.1168em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.1968em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="3.1968em" viewBox="0 0 400000 3196" preserveAspectRatio="xMinYMin slice"><path d="M702 80H40000040
H742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1
h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170
c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667
219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>超参数k值设置为10，根据最近10个邻居的标签进行多数投票（不加权投票，也是KNN算法中最常用的投票方式）。</p>
<h4 id="312-实现过程">3.1.2 实现过程</h4>
<p>基于knn.py代码实现：</p>
<pre><code class="language-python"><span class="hljs-comment"># 创建KNN分类器</span>
clf = KNeighborsClassifier(n_neighbors=<span class="hljs-number">10</span>)
<span class="hljs-comment"># 训练模型</span>
clf.fit(x_train, y_train)
<span class="hljs-comment"># 预测</span>
y_predict = clf.predict(x_test)
</code></pre>
<p>使用训练集TF-IDF特征和对应标签进行训练，对测试集样本计算与训练样本的距离，选择最近邻算法进行投票，最终预测结果。</p>
<h4 id="313-性能评估">3.1.3 性能评估</h4>
<p>使用分类报告(classification_report)评估模型性能，输出以下四个性能指标：</p>
<ul>
<li><strong>准确率</strong>: 通过预测结果与真实标签对比计算</li>
<li><strong>精确率</strong>: 各类别的预测精确度</li>
<li><strong>召回率</strong>: 各类别的样本召回能力</li>
<li><strong>F1-score</strong>: 精确率和召回率的调和平均</li>
</ul>
<p><strong>输出结果</strong>：</p>
<pre><code>              precision    recall  f1-score   support

           1       1.00      0.91      0.95        11
           2       1.00      0.91      0.95        11
           3       0.90      0.53      0.67        17
           4       0.50      0.83      0.62         6
           5       0.40      0.80      0.53         5

    accuracy                           0.76        50
   macro avg       0.76      0.80      0.75        50
weighted avg       0.85      0.76      0.77        50
</code></pre>
<h3 id="32-svm分类算法">3.2 SVM分类算法</h3>
<h4 id="321-算法原理">3.2.1 算法原理</h4>
<p>支持向量机通过寻找最优超平面实现分类：</p>
<ul>
<li><strong>核函数</strong>: 线性核(linear)，适合文本分类任务</li>
<li><strong>正则化参数</strong>: C=1.0，控制分类边界的复杂度</li>
<li><strong>优化目标</strong>: 最大化分类间隔，提高泛化能力</li>
</ul>
<h4 id="322-实现过程">3.2.2 实现过程</h4>
<p>基于svm.py代码实现：</p>
<pre><code class="language-python"><span class="hljs-comment"># 创建SVM分类器</span>
clf = SVC(kernel=<span class="hljs-string">&#x27;linear&#x27;</span>, C=<span class="hljs-number">1.0</span>)
<span class="hljs-comment"># 训练模型</span>
clf.fit(x_train, y_train)
<span class="hljs-comment"># 预测</span>
y_predict = clf.predict(x_test)
</code></pre>
<ul>
<li><strong>模型训练</strong>: 在TF-IDF特征空间寻找最优分类超平面</li>
<li><strong>线性核优势</strong>: 计算效率高，适合高维稀疏文本特征</li>
</ul>
<h4 id="323-性能评估">3.2.3 性能评估</h4>
<p>使用分类报告全面评估模型性能：</p>
<ul>
<li><strong>准确率</strong>: 整体分类正确率</li>
<li><strong>各类别指标</strong>: 精确率、召回率、F1-score</li>
<li><strong>模型对比</strong>: 与KNN算法进行性能比较</li>
</ul>
<p><strong>输出结果</strong>：</p>
<pre><code>              precision    recall  f1-score   support

           1       1.00      0.83      0.91        12
           2       0.70      0.88      0.78         8
           3       1.00      0.83      0.91        12
           4       0.70      0.88      0.78         8
           5       0.80      0.80      0.80        10

    accuracy                           0.84        50
   macro avg       0.84      0.84      0.83        50
weighted avg       0.86      0.84      0.85        50
</code></pre>
<h3 id="33-分类算法对比分析">3.3 分类算法对比分析</h3>
<table>
<thead>
<tr>
<th>算法</th>
<th>实现特点</th>
<th>适用场景</th>
<th>性能表现</th>
</tr>
</thead>
<tbody>
<tr>
<td>KNN</td>
<td>基于实例，无需显式训练</td>
<td>小数据集，特征维度适中</td>
<td>计算复杂度随数据量增加</td>
</tr>
<tr>
<td>SVM</td>
<td>基于间隔最大化，需要训练</td>
<td>高维数据，线性可分问题</td>
<td>泛化能力强，参数敏感</td>
</tr>
</tbody>
</table>
<h2 id="4-聚类算法实验">4. 聚类算法实验</h2>
<h3 id="41-k-means聚类算法">4.1 K-Means聚类算法</h3>
<h4 id="411-算法原理">4.1.1 算法原理</h4>
<p>K-Means通过迭代将数据点分配到K个簇中：</p>
<ul>
<li><strong>簇数量</strong>: k=2（根据数据特点设置）</li>
<li><strong>初始化</strong>: 默认k-means++，优化初始中心点选择</li>
<li><strong>最大迭代次数</strong>: 默认300</li>
<li><strong>收敛条件</strong>: 中心点变化小于容忍度</li>
</ul>
<h4 id="412-实现过程">4.1.2 实现过程</h4>
<p>基于kmeans.py代码实现：</p>
<pre><code class="language-python"><span class="hljs-comment"># 创建K-Means聚类器</span>
kmeans = KMeans(n_clusters=<span class="hljs-number">2</span>, random_state=<span class="hljs-number">42</span>, n_init=<span class="hljs-number">10</span>)
<span class="hljs-comment"># 拟合模型</span>
kmeans.fit(x_train)
<span class="hljs-comment"># 获取聚类标签</span>
y_pred = kmeans.labels_
</code></pre>
<ul>
<li><strong>无监督学习</strong>: 仅使用特征数据，不依赖标签信息</li>
<li><strong>聚类过程</strong>: 迭代优化簇中心，最小化簇内平方和</li>
<li><strong>结果输出</strong>: 为每个样本分配簇标签</li>
</ul>
<h4 id="413-聚类质量评估">4.1.3 聚类质量评估</h4>
<p>使用多种指标评估聚类效果：</p>
<ul>
<li><strong>调整兰德指数(ARI)</strong>: 衡量聚类结果与真实标签的一致性（有监督评估）</li>
<li><strong>轮廓系数</strong>: 衡量簇内紧密度和簇间分离度（无监督评估）</li>
<li><strong>簇内平方和</strong>: 所有样本到其所属簇中心的距离平方和</li>
</ul>
<p><strong>输出结果</strong>：</p>
<pre><code>聚类结果：
 [1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1
 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0
 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0
 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]
调整兰德指数（ARI）：0.1241
轮廓系数（Silhouette Score）：0.1422
</code></pre>
<h3 id="42-聚类结果分析">4.2 聚类结果分析</h3>
<p>成功将病理诊断文本分为2个簇：</p>
<ul>
<li><strong>簇分布</strong>: 分析各簇的样本数量和分布特征</li>
<li><strong>簇特征</strong>: 通过TF-IDF权重分析各簇的关键词汇</li>
<li><strong>临床应用</strong>: 探索聚类结果在病理诊断中的潜在意义</li>
</ul>
<h2 id="5-实验结果可视化">5. 实验结果可视化</h2>
<h3 id="51-增强版可视化功能">5.1 增强版可视化功能</h3>
<p>根据自然语言处理综合作业要求，本实验我加入了模型性能可视化评估和对比功能，支持：</p>
<ul>
<li><strong>多种向量化方法对比</strong>: TF-IDF、Count Vectorizer、Word2Vec</li>
<li><strong>ROC曲线分析</strong>: 各类别ROC曲线 + 微平均ROC曲线</li>
<li><strong>精确率-召回率曲线</strong>: 全面评估分类器性能</li>
<li><strong>增强版聚类可视化</strong>: PCA + t-SNE降维 + 轮廓系数分析</li>
<li><strong>算法综合对比</strong>: 多维度评估指标对比</li>
</ul>
<h3 id="52-综合性能对比可视化">5.2 综合性能对比可视化</h3>
<p>基于多种向量化方法的算法性能对比：
<img src="file:///d:\CODE\temp-repo\comprehensive-operation\docs\images\comprehensive_performance_comparison.svg" alt="图片3"></p>
<ul>
<li><strong>多种向量化方法</strong>: TF-IDF、Count Vectorizer、Word2Vec</li>
<li><strong>分类算法准确率</strong>: KNN (76%) vs SVM (84%)</li>
<li><strong>聚类算法评估</strong>: K-Means轮廓系数 (0.1462)</li>
<li><strong>对比分析</strong>: 不同向量化方法对算法性能的影响</li>
</ul>
<h3 id="53-roc曲线分析">5.3 ROC曲线分析</h3>
<p>展示分类算法的ROC曲线和AUC指标：
<img src="file:///d:\CODE\temp-repo\comprehensive-operation\docs\images\roc_curves.svg" alt="图片4"></p>
<ul>
<li><strong>各类别ROC曲线</strong>: 5个类别的ROC曲线和AUC值</li>
<li><strong>微平均ROC曲线</strong>: 整体分类性能评估</li>
<li><strong>AUC指标</strong>: 衡量分类器区分能力的重要指标</li>
</ul>
<h3 id="54-精确率-召回率曲线">5.4 精确率-召回率曲线</h3>
<p>展示分类算法的精确率-召回率关系：
<img src="file:///d:\CODE\temp-repo\comprehensive-operation\docs\images\precision_recall_curves.svg" alt="图片5"></p>
<ul>
<li><strong>各类别PR曲线</strong>: 5个类别的精确率-召回率曲线</li>
<li><strong>微平均PR曲线</strong>: 整体精确率-召回率表现</li>
<li><strong>平均精度(AP)</strong>: 曲线下面积，综合评估指标</li>
</ul>
<h3 id="55-增强版聚类可视化">5.5 增强版聚类可视化</h3>
<p>使用多种降维方法展示K-Means聚类结果：
<img src="file:///d:\CODE\temp-repo\comprehensive-operation\docs\images\enhanced_clustering_visualization.svg" alt="图片6"></p>
<ul>
<li><strong>PCA降维</strong>: 主成分分析降维后的聚类分布</li>
<li><strong>t-SNE降维</strong>: 非线性降维展示聚类结构</li>
<li><strong>聚类中心</strong>: 标记各簇的中心点位置</li>
<li><strong>轮廓系数分析</strong>: 评估聚类质量和簇分离度</li>
</ul>
<h3 id="56-向量化方法对比分析">5.6 向量化方法对比分析</h3>
<p>对比不同向量化方法的特征分布和性能：
<img src="file:///d:\CODE\temp-repo\comprehensive-operation\docs\images\vectorization_comparison.svg" alt="图片7"></p>
<ul>
<li><strong>特征分布</strong>: TF-IDF、Count Vectorizer、Word2Vec的特征值分布</li>
<li><strong>性能对比</strong>: 不同向量化方法下的算法准确率</li>
<li><strong>适用场景</strong>: 分析不同向量化方法的优缺点</li>
</ul>
<h2 id="6-实验代码">6. 实验代码</h2>
<h3 id="61-knn-分类模型源代码">6.1 KNN 分类模型源代码</h3>
<pre><code class="language-python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-comment"># 1、获取数据</span>
all_pd_data = pd.read_excel(<span class="hljs-string">&quot;./gastric.xlsx&quot;</span>, engine=<span class="hljs-string">&quot;openpyxl&quot;</span>)
<span class="hljs-built_in">print</span>(all_pd_data)

<span class="hljs-comment">#   * 加载停用词</span>
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./stop_words.txt&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
    stop_words = <span class="hljs-built_in">list</span>(l.strip() <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> f.readlines())
stop_words.extend([<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;（&#x27;</span>, <span class="hljs-string">&#x27;）&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>])  <span class="hljs-comment"># 由于停用词中没有&#x27;\n&#x27;和中文的左右括号和空格，所以单独再加上去</span>
<span class="hljs-built_in">print</span>(stop_words)

<span class="hljs-comment"># 2、数据预处理</span>
<span class="hljs-comment">#   * 对中文文本进行分词</span>

<span class="hljs-keyword">import</span> jieba <span class="hljs-keyword">as</span> jb
all_pd_data[<span class="hljs-string">&#x27;Cut_Text&#x27;</span>] = all_pd_data[<span class="hljs-string">&#x27;Text&#x27;</span>].apply(
    <span class="hljs-keyword">lambda</span> x: <span class="hljs-string">&quot; &quot;</span>.join([w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(jb.cut(x)) <span class="hljs-keyword">if</span> w <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words]))

<span class="hljs-built_in">print</span>(all_pd_data)

<span class="hljs-comment">#   * 划分训练集和测试集 （按照Label采用分层抽样，保证训练集和测试集样本均匀）</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
x_train, x_test,y_train,y_test = train_test_split(all_pd_data[<span class="hljs-string">&#x27;Cut_Text&#x27;</span>],all_pd_data[<span class="hljs-string">&#x27;Label&#x27;</span>],test_size=<span class="hljs-number">0.2</span>, stratify=all_pd_data[<span class="hljs-string">&#x27;Label&#x27;</span>])
<span class="hljs-comment"># 3、特征工程</span>

<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer

<span class="hljs-comment"># 3.1、求出训练集 tf-idf</span>
<span class="hljs-comment"># 3.1.1、实例化一个转换器类</span>
transfer = TfidfVectorizer(stop_words=stop_words)
<span class="hljs-comment"># 3.1.2、调用 fit_transform</span>
x_train = transfer.fit_transform(x_train)
x_test = transfer.transform(x_test)
<span class="hljs-comment"># 打印特征抽取结果</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;文本特征抽取的结果：\n&quot;</span>, x_train)
<span class="hljs-comment"># 新版本使用 get_feature_names_out()</span>
feature_names = transfer.get_feature_names_out()
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;返回特征名字：\n&quot;</span>, feature_names)
x_train_feature = feature_names.tolist()
y_train = <span class="hljs-built_in">list</span>(y_train)
y_test = <span class="hljs-built_in">list</span>(y_test)

<span class="hljs-built_in">print</span>(x_train.shape)  <span class="hljs-comment"># (200, 80)</span>

<span class="hljs-comment"># 4、构建KNN模型</span>
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier
clf =  KNeighborsClassifier(n_neighbors=<span class="hljs-number">10</span>)
clf.fit(x_train, y_train) <span class="hljs-comment"># 训练数据</span>
y_predict = clf.predict(x_test)

<span class="hljs-comment">#5、评估模型</span>

<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report
<span class="hljs-built_in">print</span>(classification_report(y_predict, y_test))
</code></pre>
<h3 id="62-svm-分类模型源代码">6.2 SVM 分类模型源代码</h3>
<pre><code class="language-python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-comment"># 1、获取数据</span>
all_pd_data = pd.read_excel(<span class="hljs-string">&quot;./gastric.xlsx&quot;</span>, engine=<span class="hljs-string">&quot;openpyxl&quot;</span>)
<span class="hljs-built_in">print</span>(all_pd_data)

<span class="hljs-comment">#   * 加载停用词</span>
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./stop_words.txt&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
    stop_words = [l.strip() <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> f.readlines()]
stop_words.extend([<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;（&#x27;</span>, <span class="hljs-string">&#x27;）&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>])
<span class="hljs-built_in">print</span>(stop_words)

<span class="hljs-comment"># 2、数据预处理</span>
<span class="hljs-comment">#   * 对中文文本进行分词</span>
<span class="hljs-keyword">import</span> jieba <span class="hljs-keyword">as</span> jb
all_pd_data[<span class="hljs-string">&#x27;Cut_Text&#x27;</span>] = all_pd_data[<span class="hljs-string">&#x27;Text&#x27;</span>].apply(
    <span class="hljs-keyword">lambda</span> x: <span class="hljs-string">&quot; &quot;</span>.join([w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(jb.cut(x)) <span class="hljs-keyword">if</span> w <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words])
)

<span class="hljs-built_in">print</span>(all_pd_data)

<span class="hljs-comment">#   * 划分训练集和测试集（分层抽样，保证比例一致）</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
x_train, x_test, y_train, y_test = train_test_split(
    all_pd_data[<span class="hljs-string">&#x27;Cut_Text&#x27;</span>],
    all_pd_data[<span class="hljs-string">&#x27;Label&#x27;</span>],
    test_size=<span class="hljs-number">0.2</span>,
    stratify=all_pd_data[<span class="hljs-string">&#x27;Label&#x27;</span>]
)

<span class="hljs-comment"># 3、特征工程</span>
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer

<span class="hljs-comment"># 3.1、求出训练集 tf-idf</span>
transfer = TfidfVectorizer(stop_words=stop_words)
x_train = transfer.fit_transform(x_train)
x_test = transfer.transform(x_test)

<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;文本特征抽取的结果：\n&quot;</span>, x_train)
feature_names = transfer.get_feature_names_out()
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;返回特征名字：\n&quot;</span>, feature_names)
x_train_feature = feature_names.tolist()
y_train = <span class="hljs-built_in">list</span>(y_train)
y_test = <span class="hljs-built_in">list</span>(y_test)

<span class="hljs-built_in">print</span>(x_train.shape)  <span class="hljs-comment"># 比如 (200, 80)</span>

<span class="hljs-comment"># 4、构建SVM模型</span>
<span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC

<span class="hljs-comment">#   * 实例化SVM分类器</span>
<span class="hljs-comment">#   * kernel=&#x27;linear&#x27; 使用线性核函数，常见还有 &#x27;rbf&#x27;, &#x27;poly&#x27;</span>
clf = SVC(kernel=<span class="hljs-string">&#x27;linear&#x27;</span>, C=<span class="hljs-number">1.0</span>)
clf.fit(x_train, y_train)

<span class="hljs-comment">#   * 预测</span>
y_predict = clf.predict(x_test)

<span class="hljs-comment"># 5、评估模型</span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report
<span class="hljs-built_in">print</span>(classification_report(y_predict, y_test))
</code></pre>
<h3 id="63-k-means-聚类模型源代码">6.3 K-Means 聚类模型源代码</h3>
<pre><code class="language-python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-comment"># 1、获取数据</span>
all_pd_data = pd.read_excel(<span class="hljs-string">&quot;./gastric.xlsx&quot;</span>, engine=<span class="hljs-string">&quot;openpyxl&quot;</span>)
<span class="hljs-built_in">print</span>(all_pd_data)

<span class="hljs-comment">#   * 加载停用词</span>
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./stop_words.txt&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
    stop_words = [l.strip() <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> f.readlines()]
stop_words.extend([<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27;（&#x27;</span>, <span class="hljs-string">&#x27;）&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>])
<span class="hljs-built_in">print</span>(stop_words)

<span class="hljs-comment"># 2、数据预处理</span>
<span class="hljs-comment">#   * 对中文文本进行分词</span>
<span class="hljs-keyword">import</span> jieba <span class="hljs-keyword">as</span> jb
all_pd_data[<span class="hljs-string">&#x27;Cut_Text&#x27;</span>] = all_pd_data[<span class="hljs-string">&#x27;Text&#x27;</span>].apply(
    <span class="hljs-keyword">lambda</span> x: <span class="hljs-string">&quot; &quot;</span>.join([w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(jb.cut(x)) <span class="hljs-keyword">if</span> w <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words])
)

<span class="hljs-built_in">print</span>(all_pd_data)

<span class="hljs-comment">#   * 注意：KMeans是无监督学习，不需要划分标签</span>
<span class="hljs-comment">#     但如果你的数据中有 Label，我们可以用来对聚类结果进行对比评估</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
x_train, x_test, y_train, y_test = train_test_split(
    all_pd_data[<span class="hljs-string">&#x27;Cut_Text&#x27;</span>],
    all_pd_data[<span class="hljs-string">&#x27;Label&#x27;</span>],
    test_size=<span class="hljs-number">0.2</span>,
    stratify=all_pd_data[<span class="hljs-string">&#x27;Label&#x27;</span>]
)

<span class="hljs-comment"># 3、特征工程</span>
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer

<span class="hljs-comment"># 3.1、求出 tf-idf 特征</span>
transfer = TfidfVectorizer(stop_words=stop_words)
x_train = transfer.fit_transform(x_train)
x_test = transfer.transform(x_test)

<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;文本特征抽取的结果：\n&quot;</span>, x_train)
feature_names = transfer.get_feature_names_out()
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;返回特征名字：\n&quot;</span>, feature_names)
x_train_feature = feature_names.tolist()

<span class="hljs-built_in">print</span>(x_train.shape)  <span class="hljs-comment"># 比如 (200, 80)</span>

<span class="hljs-comment"># 4、构建 K-Means 模型</span>
<span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans

<span class="hljs-comment">#   * 实例化聚类器，n_clusters 设置为聚类数（通常与类别数相同）</span>
kmeans = KMeans(n_clusters=<span class="hljs-number">2</span>, random_state=<span class="hljs-number">42</span>, n_init=<span class="hljs-number">10</span>)
kmeans.fit(x_train)

<span class="hljs-comment">#   * 获取聚类结果</span>
y_pred = kmeans.labels_
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;聚类结果：\n&quot;</span>, y_pred)

<span class="hljs-comment"># 5、评估模型（仅在有标签时可用于评估）</span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> adjusted_rand_score, silhouette_score

<span class="hljs-comment">#   * ARI 衡量聚类与真实标签的一致性（有标签时）</span>
ari = adjusted_rand_score(y_train, y_pred)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;调整兰德指数（ARI）：<span class="hljs-subst">{ari:<span class="hljs-number">.4</span>f}</span>&quot;</span>)

<span class="hljs-comment">#   * 轮廓系数 衡量聚类的紧密度和分离度（无监督评价）</span>
sil = silhouette_score(x_train, y_pred)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;轮廓系数（Silhouette Score）：<span class="hljs-subst">{sil:<span class="hljs-number">.4</span>f}</span>&quot;</span>)
</code></pre>
<h2 id="7-实验总结与展望">7. 实验总结与展望</h2>
<h3 id="71-主要成果">7.1 主要成果</h3>
<p>本次实验，我通过机器学习算法，对一个病理诊断数据集进行分类和聚类，并利用可视化技术绘制了不同算法的图像，用于分析算法的好坏。</p>
<h3 id="72-技术挑战与解决方案">7.2 技术挑战与解决方案</h3>
<p>根据图像可知，KNN算法和SVM算法的结果较好，但K-Means算法的结果较差。</p>
<h3 id="74-未来工作">7.4 未来工作</h3>
<ul>
<li>继续优化分类算法，例如使用交叉验证调整超参数k的值，达到更好的分类结果。</li>
<li>完善K-Means聚类算法</li>
</ul>
<hr>
<p><strong>完成时间：</strong> 2025年11月4日<br>
<strong>备注：</strong> 为了证明本作业的原创性，该项目的所有代码、设计稿、Markdown格式文档等均公开，项目已开源到Github平台。项目作者为圣逸凡，开源协议为GPLv3，可访问<a href="https://github.com/my269yf/comprehensive-operation">项目链接</a>查看源代码。</p>

            <script async src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
            
        </body>
        </html>